\section{Related Work}
Early research on software project forecasting emphasized probabilistic reasoning to complement deterministic schedule estimates. Kitchenham and colleagues surveyed Monte Carlo applications for software cost modeling, showing how simulation can capture uncertainty in productivity and defect-removal effort \cite{Kitchenham2002}. Later, Lipke's Earned Schedule framework incorporated stochastic duration modeling to improve earned value management accuracy \cite{Lipke2009}. Contemporary agile studies, such as those by Vacanti, operationalized throughput-based Monte Carlo simulations for short iteration planning, albeit with limited tooling support and scarce validation artifacts \cite{Vacanti2018}. Flow Forecaster extends this lineage by providing a production-grade, reproducible Monte Carlo engine embedded into a web application, enabling thousands of samples per scenario along with deadline-aware analytics.

Parallel advances in data-driven forecasting explored machine learning regression on software process data. Minku and Yao demonstrated that ensemble learning could outperform traditional models when project data exhibits concept drift, encouraging adaptive pipelines for effort estimation \cite{Minku2012}. Mittas and Angelis benchmarked regression techniques on industrial datasets, highlighting the need for rigorous cross-validation and error distribution analysis \cite{Mittas2013}. More recently, Hasan et al.\ employed gradient boosting and quantile regression to predict story completion times in agile teams, underscoring the value of predictive intervals over point forecasts \cite{Hasan2021}. Flow Forecaster synthesizes these ideas by combining Random Forest, HistGradient Boosting (including quantile variants), XGBoost, and classical baselines with explicit time-series cross-validation.

Hybrid approaches that merge simulation and ML remain comparatively rare. Saber et al.\ proposed a pipeline that calibrates simulation parameters from ML predictions, yet the implementation lacked accessible tooling for practitioner experimentation \cite{Saber2019}. Flow Forecaster contributes a fully realized integration: the Monte Carlo engine shares feature engineering and diagnostic components with the ML subsystem, and regression tests ensure percentile estimates remain statistically coherent across both paradigms. This synthesis addresses the reproducibility and operationalization gaps noted in prior work, while offering a foundation for comparative studies between probabilistic and learning-based forecasting in software engineering contexts.
