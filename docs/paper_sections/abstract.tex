\begin{abstract}
We present Flow Forecaster, a web-based analytics platform that combines Monte Carlo simulation and multi-model machine learning to predict software project throughput, lead time, and deadline adherence. By reverse-engineering the publicly available implementation, we document an experimentation pipeline that ingests historical throughput traces, constructs lagged statistical features, and executes ensembles of Random Forest, HistGradient Boosting (median and quantile variants), XGBoost, and classical baselines under time-series cross-validation. The Monte Carlo engine mirrors the browser implementation while extending it with dependency-aware risk modeling, probabilistic capacity tables, and deadline diagnostics driven by $10{,}000$-sample simulations. Static and dynamic validation artifacts embedded in the code base---including walk-forward backtesting modules, probability-table regression tests, and deadline verifiers---show MAE/RMSE tracking, percentile forecasts consistent with theoretical expectations (e.g., P85 capacity exceeding a 25-item backlog within a four-week horizon), and coherent risk classifications used to trigger portfolio alerts. These findings position Flow Forecaster as a research-grade environment for empirically comparing probabilistic and data-driven forecasting in software engineering.
\end{abstract}
